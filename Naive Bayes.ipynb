{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from get_data import data\n",
    "from sklearn.cross_validation import train_test_split\n",
    "\n",
    "from naivebayes import NaiveBayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pd.set_option('max_rows', 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class NaiveBayes:\n",
    "    \n",
    "    def __init__(self, ignore_missing=False):\n",
    "        \"\"\"\n",
    "        Initialize a NaiveBayes object.\n",
    "            \n",
    "        Parameters\n",
    "        ----------\n",
    "        ignore_missing : boolean (Default: False)\n",
    "            Whether to ignore feature that contain missing values\n",
    "            \n",
    "        Attributes\n",
    "        ----------\n",
    "        learned_params : dict\n",
    "            Parameters learned from the Naive Bayes model\n",
    "        features : list(str)\n",
    "            Labels of all features to use\n",
    "        categorical_features : list(str)\n",
    "            Labels of features that are categorical\n",
    "        \"\"\"\n",
    "        self.ignore_missing = ignore_missing\n",
    "        \n",
    "        if self.ignore_missing:\n",
    "            self.features = ['age', 'fnlwgt', 'education', 'education-num', 'marital-status', \\\n",
    "                            'relationship', 'race', 'sex', 'capital-gain', 'capital-loss', \\\n",
    "                            'hours-per-week']\n",
    "            self.categorical_features = ['education', 'marital-status', 'relationship', 'race', 'sex']\n",
    "            \n",
    "        else:\n",
    "            self.features = ['age', 'workclass', 'fnlwgt', 'education', 'education-num', 'marital-status', \\\n",
    "                            'occupation', 'relationship', 'race', 'sex', 'capital-gain', 'capital-loss', \\\n",
    "                            'hours-per-week', 'native-country']\n",
    "            self.categorical_features = ['workclass', 'education', 'marital-status', 'occupation', \n",
    "                        'relationship', 'race', 'sex', 'native-country']\n",
    "            \n",
    "        self.learned_params = None\n",
    "        \n",
    "            \n",
    "    def gaussian_pdf(self, mu, sigma, x):\n",
    "        \"\"\"\n",
    "        Returns the probability of a point x according to a Gaussian distribution\n",
    "        with mean mu and standard deviation sigma.\n",
    "        \"\"\"\n",
    "        return 1/(sigma * np.sqrt(2 * np.pi))*np.exp( - (x - mu)**2 / (2 * sigma**2) )\n",
    "    \n",
    "    \n",
    "    def score(self, samples):\n",
    "        \"\"\"\n",
    "        Return the classification accuracy for a given set of samples.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        samples : pandas DataFrame\n",
    "            - Samples of data to predict\n",
    "            \n",
    "        Returns\n",
    "        ----------\n",
    "            - (Float) The classification accuracy of the Bayes model on the samples\n",
    "        \"\"\"\n",
    "        y_pred = self.classify(samples.to_dict(orient='records'))\n",
    "        y_true = samples['class'].tolist()\n",
    "        \n",
    "        return np.mean( np.array(y_true) == np.array(y_pred) )\n",
    "        \n",
    "            \n",
    "    def classify(self, samples):\n",
    "        \"\"\"\n",
    "        Classifies new data points according to the Naive Bayes model learned from\n",
    "        the learn_parameters function. \n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        samples : pandas DataFrame\n",
    "            The samples of data to classify\n",
    "            \n",
    "        Returns\n",
    "        ----------\n",
    "            - (List) The predicted class labeles for each of the samples.\n",
    "        \"\"\"\n",
    "        \n",
    "        if self.learned_params is None:\n",
    "            print('Please call learn_parameters to fit the Naive Bayes model.')\n",
    "            return\n",
    "            \n",
    "        predictions = []\n",
    "        \n",
    "        categorical_features = self.categorical_features\n",
    "        learned_params = self.learned_params\n",
    "        \n",
    "        for sample in samples:\n",
    "            \n",
    "            class_0 = []\n",
    "            class_1 = []\n",
    "            \n",
    "            for feature in sample:\n",
    "                if feature in learned_params:\n",
    "                    \n",
    "                    value = sample[feature]\n",
    "                    \n",
    "                    if feature in categorical_features:\n",
    "                        class_0_prob = learned_params[feature][value][0]\n",
    "                        class_1_prob = learned_params[feature][value][1]\n",
    "                        class_0.append(class_0_prob)\n",
    "                        class_1.append(class_1_prob)\n",
    "                    else:\n",
    "                        c0_mean = learned_params[feature][0]['mean']\n",
    "                        c0_std = learned_params[feature][0]['std']\n",
    "                        c1_mean = learned_params[feature][1]['mean']\n",
    "                        c1_std = learned_params[feature][1]['std']\n",
    "                        class_0_prob = self.gaussian_pdf(c0_mean, c0_std, value)\n",
    "                        class_1_prob = self.gaussian_pdf(c1_mean, c1_std, value)\n",
    "                        class_0.append(class_0_prob)\n",
    "                        class_1.append(class_1_prob)\n",
    "                        \n",
    "            c_0_prob = np.prod(class_0)\n",
    "            c_1_prob = np.prod(class_1)\n",
    "                    \n",
    "            if c_0_prob > c_1_prob:\n",
    "                predictions.append(0)\n",
    "            else:\n",
    "                predictions.append(1)\n",
    "                        \n",
    "        return predictions\n",
    "        \n",
    "            \n",
    "    def learn_parameters(self, training_set):\n",
    "        \"\"\"\n",
    "        Learn the parameters for the Naive Bayes model according to the data.\n",
    "        \n",
    "        If the feature is categorical, the parameter learned are the fraction\n",
    "        of the samples containing a particular value for that feature, per class.\n",
    "        \n",
    "        If the feature is numerical, the parameters learned are the mean and \n",
    "        standard deviation of the feature, per class.\n",
    "        \n",
    "        These parameters are stored in the object atribute `learned_params`.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        training_set : pandas DataFrame\n",
    "            The data from which to learn the Naive Bayes model\n",
    "        \"\"\"\n",
    "        df = training_set\n",
    "        \n",
    "        features = self.features\n",
    "        categorical_features = self.categorical_features\n",
    "\n",
    "        num_class_0 = df[df['class'] == 0].shape[0]\n",
    "        num_class_1 = df[df['class'] == 1].shape[0]\n",
    "\n",
    "        # Hold the learned parameters\n",
    "        # Mean and std for continuous quantities\n",
    "        # Feature-value probabilities for categorical data\n",
    "        learned_probabilities = {}\n",
    "\n",
    "        for feature in features:\n",
    "\n",
    "            # Learn probabilities for categorical variables\n",
    "            if feature in categorical_features:  \n",
    "                # List of unique values the feature can take\n",
    "                unique_values = df[feature].unique()\n",
    "                # Probabilities for given values conditioned on class\n",
    "                conditional_probs = {}\n",
    "\n",
    "                # Calculate these probabilities\n",
    "                for value in unique_values:\n",
    "                    class_0_prob = df[ (df[feature] == value) & (df['class'] == 0) ].shape[0] / float(num_class_0)\n",
    "                    class_1_prob = df[ (df[feature] == value) & (df['class'] == 1) ].shape[0] / float(num_class_1)\n",
    "                    conditional_probs[value] = {0 : class_0_prob, 1 : class_1_prob}\n",
    "\n",
    "                learned_probabilities[feature] = conditional_probs\n",
    "\n",
    "            else:\n",
    "                # Get the mean and std for each class\n",
    "                class_0_mean = df[ df['class'] == 0 ][feature].mean()\n",
    "                class_0_std = df[ df['class'] == 0 ][feature].std()\n",
    "                class_1_mean = df[ df['class'] == 1 ][feature].mean()\n",
    "                class_1_std = df[ df['class'] == 1 ][feature].std()\n",
    "\n",
    "                learned_probabilities[feature] = {0:{'mean': class_0_mean, 'std': class_0_std},\n",
    "                                                  1: {'mean': class_1_mean, 'std': class_1_std}}\n",
    "                \n",
    "        self.learned_params = learned_probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: 0.5 Test error: 0.169103194103 Ignore missing: True\n",
      "Train size: 0.5 Test error: 0.161670761671 Ignore missing: False\n",
      "Train size: 0.6 Test error: 0.169750479846 Ignore missing: True\n",
      "Train size: 0.6 Test error: 0.161996161228 Ignore missing: False\n",
      "Train size: 0.7 Test error: 0.168799262975 Ignore missing: True\n",
      "Train size: 0.7 Test error: 0.15979117617 Ignore missing: False\n",
      "Train size: 0.8 Test error: 0.165515123599 Ignore missing: True\n",
      "Train size: 0.8 Test error: 0.155688622754 Ignore missing: False\n",
      "Train size: 0.9 Test error: 0.165182683451 Ignore missing: True\n",
      "Train size: 0.9 Test error: 0.151673319005 Ignore missing: False\n"
     ]
    }
   ],
   "source": [
    "for train_size in np.linspace(.5, .9, 5):\n",
    "    \n",
    "    train, test = train_test_split(df, train_size=train_size, random_state=42)\n",
    "\n",
    "    # Since there is only 1 sample with native-country == Holand-Netherlands,\n",
    "    # ensure that this sample is in the training set\n",
    "    if 'Holand-Netherlands' in test['native-country'].unique():\n",
    "        train = train.append( test[test['native-country'] == 'Holand-Netherlands'] )\n",
    "        test = test[ test['native-country'] != 'Holand-Netherlands']\n",
    "\n",
    "    for ignore_missing in [True, False]:\n",
    "        nb = NaiveBayes(ignore_missing=ignore_missing)\n",
    "\n",
    "        nb.learn_parameters(train)\n",
    "        acc = nb.score(test[ test['native-country'] != 'Holand-Netherlands'])\n",
    "\n",
    "        print('Train size: {} Test error: {} Ignore missing: {}'.format(train_size, (1-acc), ignore_missing))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
